{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f786a078",
   "metadata": {},
   "source": [
    "# Learning a quadratic pseudo-metric from distance measurements\n",
    "\n",
    "We are given a set of $N$ pairs of points in $\\mathbf{R}^n$, $x_1, \\ldots, x_N$, and $y_1, \\ldots, y_N$, together with a set of distances $d_1, \\ldots, d_N > 0$.\n",
    "  The goal is to find (or estimate or learn) a quadratic pseudo-metric $d$\n",
    "  $$d(x,y) =  \\left( (x-y)^T P(x-y) \\right)^{1/2},$$\n",
    "  $P\\in \\mathbf{S}^n_{+}$, which approximates the given distances, i.e., $d(x_i, y_i) \\approx d_i$. (The pseudo-metric $d$ is a metric only when $P \\succ 0$; when $P\\succeq 0$ is singular, it is a pseudo-metric.)\n",
    "  \n",
    "  To do this, we will choose $P\\in \\mathbf{S}^n_+$ that minimizes the mean squared error objective\n",
    "  \n",
    "  $$\\frac{1}{N}\\sum_{i=1}^N (d_i - d(x_i,y_i))^2.$$\n",
    "  \n",
    "  Show that this is a convex function and with the constraint $P\\succeq 0$ it defines an SDP. Hint: expand the square and see what happens.\n",
    "  \n",
    "  Solve the SDP. (You can use modelling packages like ``cvxpy``.)\n",
    "  \n",
    "  Then, use the obtained $P$ to measure the mean square error for the test data ``X_test``, ``Y_test``, ``d_test``.\n",
    "  \n",
    "---- \n",
    "*This exercise originates from \"Additional Exercises\" collection for Convex Optimization textbook of S. Boyd and L. Vandenberghe. Used under permission*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8da0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e0d2b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2041)\n",
    "\n",
    "n = 5 # Dimension\n",
    "N = 100 # Number of samples\n",
    "\n",
    "P = np.random.randn(n,n)\n",
    "P = P.dot(P.T) + np.identity(n)\n",
    "sqrtP = la.sqrtm(P)\n",
    "\n",
    "x = np.random.randn(N,n)\n",
    "y = np.random.randn(N,n)\n",
    "\n",
    "d = np.linalg.norm(sqrtP.dot((x-y).T),axis=0)    # distances according to metric P\n",
    "d = np.maximum(d+np.random.randn(N),0)           # add random noise\n",
    "\n",
    "N_test = 10 # Samples for test set\n",
    "X_test = np.random.randn(N_test,n)\n",
    "Y_test = np.random.randn(N_test,n)\n",
    "d_test = np.linalg.norm(sqrtP.dot((X_test-Y_test).T),axis=0)  # distances according to metric P\n",
    "d_test = np.maximum(d_test+np.random.randn(N_test),0)         # add random noise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
